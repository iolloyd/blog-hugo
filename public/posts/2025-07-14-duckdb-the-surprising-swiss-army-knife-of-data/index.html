<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>DuckDB: The Surprising Swiss Army Knife of Data Processing | Lloyd Moore</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="DuckDB isn&#39;t just &#39;SQLite for analytics.&#39; It&#39;s a tool that makes impossible data tasks trivial, from analyzing S3 files without downloading to replacing entire ETL pipelines with a single SQL query.">
    <meta name="generator" content="Hugo 0.150.0">
    
    
    
      <meta name="robots" content="index, follow">
    
    

    
<link rel="stylesheet" href="/ananke/css/main.min.2438bcafd7af9675c426d1a4afcd16cfff18e4e10f401071e45b5ccd3be40a0d.css" >




    


    
      

    

    

    
      <link rel="canonical" href="https://lloydmoore.com/posts/2025-07-14-duckdb-the-surprising-swiss-army-knife-of-data/">
    

    <meta property="og:url" content="https://lloydmoore.com/posts/2025-07-14-duckdb-the-surprising-swiss-army-knife-of-data/">
  <meta property="og:site_name" content="Lloyd Moore">
  <meta property="og:title" content="DuckDB: The Surprising Swiss Army Knife of Data Processing">
  <meta property="og:description" content="DuckDB isn&#39;t just &#39;SQLite for analytics.&#39; It&#39;s a tool that makes impossible data tasks trivial, from analyzing S3 files without downloading to replacing entire ETL pipelines with a single SQL query.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-07-14T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-07-14T00:00:00+00:00">
    <meta property="article:tag" content="Duckdb">
    <meta property="article:tag" content="Data-Processing">
    <meta property="article:tag" content="Analytics">
    <meta property="article:tag" content="Sql">
    <meta property="article:tag" content="Performance">

  <meta itemprop="name" content="DuckDB: The Surprising Swiss Army Knife of Data Processing">
  <meta itemprop="description" content="DuckDB isn&#39;t just &#39;SQLite for analytics.&#39; It&#39;s a tool that makes impossible data tasks trivial, from analyzing S3 files without downloading to replacing entire ETL pipelines with a single SQL query.">
  <meta itemprop="datePublished" content="2025-07-14T00:00:00+00:00">
  <meta itemprop="dateModified" content="2025-07-14T00:00:00+00:00">
  <meta itemprop="wordCount" content="1177">
  <meta itemprop="keywords" content="Duckdb,Data-Processing,Analytics,Sql,Performance">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="DuckDB: The Surprising Swiss Army Knife of Data Processing">
  <meta name="twitter:description" content="DuckDB isn&#39;t just &#39;SQLite for analytics.&#39; It&#39;s a tool that makes impossible data tasks trivial, from analyzing S3 files without downloading to replacing entire ETL pipelines with a single SQL query.">

      
    
	
  </head><body class="ma0 avenir bg-near-white production">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <a href="/" class="f3 fw2 hover-white white-90 dib no-underline">
      
        Lloyd Moore
      
    </a>
    <div class="flex-l items-center">
      

      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  
  <article class="flex-l mw8 center ph3 flex-wrap justify-between">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        Posts
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">DuckDB: The Surprising Swiss Army Knife of Data Processing</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2025-07-14T00:00:00Z">July 14, 2025</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h1 id="duckdb-making-the-impossible-simple">DuckDB: Making the Impossible Simple</h1>
<p>Last week, someone asked to analyze 50GB of CSV files scattered across S3. Five years ago, this would&rsquo;ve meant spinning up a Spark cluster. Today? One line of DuckDB SQL.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">SELECT</span> customer_id, <span style="color:#66d9ef">SUM</span>(amount) <span style="color:#66d9ef">as</span> total_spent
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">FROM</span> read_csv_auto(<span style="color:#e6db74">&#39;s3://mybucket/transactions/*.csv&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">WHERE</span> transaction_date <span style="color:#f92672">&gt;</span> <span style="color:#e6db74">&#39;2025-01-01&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">GROUP</span> <span style="color:#66d9ef">BY</span> customer_id
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">ORDER</span> <span style="color:#66d9ef">BY</span> total_spent <span style="color:#66d9ef">DESC</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">LIMIT</span> <span style="color:#ae81ff">100</span>;
</span></span></code></pre></div><p>No cluster. No downloads. No loading. Just query the files where they sit.</p>
<p>This is DuckDB&rsquo;s superpower: it makes difficult data tasks surprisingly simple.</p>
<h2 id="what-is-duckdb">What Is DuckDB?</h2>
<p>Think of DuckDB like an analytically-gifted SQLite. It&rsquo;s an in-process SQL database designed for analytics, but that description massively undersells it. DuckDB is more like a Swiss Army knife for data â€“ a single tool that replaces dozens of specialised ones.</p>
<p>Key characteristics:</p>
<ul>
<li><strong>Embedded</strong>: No server, just import and use</li>
<li><strong>Columnar storage</strong>: Optimized for analytical queries</li>
<li><strong>Zero dependencies</strong>: Single binary, works everywhere</li>
<li><strong>Vectorized execution</strong>: Processes data in chunks for speed</li>
<li><strong>SQL-first</strong>: If you know SQL, you know DuckDB</li>
</ul>
<p>But here&rsquo;s what the documentation doesn&rsquo;t explain: DuckDB is great at jobs you wouldn&rsquo;t expect a database to handle at all.</p>
<h2 id="surprising-use-case-1-the-universal-file-reader">Surprising Use Case #1: The Universal File Reader</h2>
<p>Forget writing parsers. DuckDB reads everything:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#75715e">-- Query CSV files
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> <span style="color:#e6db74">&#39;data.csv&#39;</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- Query JSON files
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> <span style="color:#e6db74">&#39;api_response.json&#39;</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- Query Parquet files
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> <span style="color:#e6db74">&#39;analytics/*.parquet&#39;</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- Query Excel files (with spatial extension)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> <span style="color:#e6db74">&#39;report.xlsx&#39;</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- Mix and match!
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">SELECT</span> 
</span></span><span style="display:flex;"><span>    csv.user_id,
</span></span><span style="display:flex;"><span>    json.preferences,
</span></span><span style="display:flex;"><span>    parquet.transaction_history
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">FROM</span> <span style="color:#e6db74">&#39;users.csv&#39;</span> csv
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">JOIN</span> <span style="color:#e6db74">&#39;preferences.json&#39;</span> json <span style="color:#66d9ef">ON</span> csv.user_id <span style="color:#f92672">=</span> json.user_id
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">JOIN</span> <span style="color:#e6db74">&#39;transactions/*.parquet&#39;</span> parquet <span style="color:#66d9ef">ON</span> csv.user_id <span style="color:#f92672">=</span> parquet.user_id;
</span></span></code></pre></div><p>No schema definition. No CREATE TABLE. DuckDB infers everything and just works.</p>
<h2 id="surprising-use-case-2-git-repository-analyst">Surprising Use Case #2: Git Repository Analyst</h2>
<p>Want to analyze your Git history? DuckDB can query it directly:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#75715e">-- Install git extension
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>INSTALL git;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">LOAD</span> git;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- Find most modified files
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">SELECT</span> 
</span></span><span style="display:flex;"><span>    file_path,
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">COUNT</span>(<span style="color:#f92672">*</span>) <span style="color:#66d9ef">as</span> modifications,
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">COUNT</span>(<span style="color:#66d9ef">DISTINCT</span> author_name) <span style="color:#66d9ef">as</span> unique_authors
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">FROM</span> git_log(<span style="color:#e6db74">&#39;.&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">WHERE</span> file_path <span style="color:#66d9ef">LIKE</span> <span style="color:#e6db74">&#39;%.py&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">GROUP</span> <span style="color:#66d9ef">BY</span> file_path
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">ORDER</span> <span style="color:#66d9ef">BY</span> modifications <span style="color:#66d9ef">DESC</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">LIMIT</span> <span style="color:#ae81ff">20</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- Analyze commit patterns
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">SELECT</span> 
</span></span><span style="display:flex;"><span>    DATE_TRUNC(<span style="color:#e6db74">&#39;hour&#39;</span>, commit_date) <span style="color:#66d9ef">as</span> hour,
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">COUNT</span>(<span style="color:#f92672">*</span>) <span style="color:#66d9ef">as</span> commits
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">FROM</span> git_log(<span style="color:#e6db74">&#39;.&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">WHERE</span> commit_date <span style="color:#f92672">&gt;</span> NOW() <span style="color:#f92672">-</span> INTERVAL <span style="color:#e6db74">&#39;30 days&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">GROUP</span> <span style="color:#66d9ef">BY</span> hour
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">ORDER</span> <span style="color:#66d9ef">BY</span> hour;
</span></span></code></pre></div><p>This replaced a 200-line Python script with 10 lines of SQL.</p>
<h2 id="surprising-use-case-3-the-pandas-replacement">Surprising Use Case #3: The Pandas Replacement</h2>
<p>Data scientists, take note. DuckDB often outperforms pandas while using standard SQL:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Old way with pandas</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>df1 <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;sales_2023.csv&#39;</span>)
</span></span><span style="display:flex;"><span>df2 <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;sales_2024.csv&#39;</span>)
</span></span><span style="display:flex;"><span>combined <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat([df1, df2])
</span></span><span style="display:flex;"><span>result <span style="color:#f92672">=</span> combined<span style="color:#f92672">.</span>groupby(<span style="color:#e6db74">&#39;product_id&#39;</span>)<span style="color:#f92672">.</span>agg({
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;quantity&#39;</span>: <span style="color:#e6db74">&#39;sum&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;revenue&#39;</span>: <span style="color:#e6db74">&#39;sum&#39;</span>
</span></span><span style="display:flex;"><span>})<span style="color:#f92672">.</span>reset_index()
</span></span><span style="display:flex;"><span>result<span style="color:#f92672">.</span>to_parquet(<span style="color:#e6db74">&#39;summary.parquet&#39;</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># New way with DuckDB</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> duckdb
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>duckdb<span style="color:#f92672">.</span>sql(<span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    COPY (
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        SELECT 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            product_id,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            SUM(quantity) as total_quantity,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            SUM(revenue) as total_revenue
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        FROM read_csv_auto([&#39;sales_2023.csv&#39;, &#39;sales_2024.csv&#39;])
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        GROUP BY product_id
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ) TO &#39;summary.parquet&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;</span>)
</span></span></code></pre></div><p>Same result. 10x faster. Uses 5x less memory.</p>
<h2 id="surprising-use-case-4-log-file-detective">Surprising Use Case #4: Log File Detective</h2>
<p>System logs giving you trouble? DuckDB handles unstructured data brilliantly:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#75715e">-- Parse nginx logs
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">WITH</span> parsed_logs <span style="color:#66d9ef">AS</span> (
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">SELECT</span> 
</span></span><span style="display:flex;"><span>        regexp_extract(line, <span style="color:#e6db74">&#39;(\d+\.\d+\.\d+\.\d+)&#39;</span>, <span style="color:#ae81ff">1</span>) <span style="color:#66d9ef">as</span> ip,
</span></span><span style="display:flex;"><span>        regexp_extract(line, <span style="color:#e6db74">&#39;\[([^\]]+)\]&#39;</span>, <span style="color:#ae81ff">1</span>) <span style="color:#66d9ef">as</span> <span style="color:#66d9ef">timestamp</span>,
</span></span><span style="display:flex;"><span>        regexp_extract(line, <span style="color:#e6db74">&#39;&#34;(\w+) ([^&#34;]+)&#34;&#39;</span>, <span style="color:#ae81ff">1</span>) <span style="color:#66d9ef">as</span> <span style="color:#66d9ef">method</span>,
</span></span><span style="display:flex;"><span>        regexp_extract(line, <span style="color:#e6db74">&#39;&#34;(\w+) ([^&#34;]+)&#34;&#39;</span>, <span style="color:#ae81ff">2</span>) <span style="color:#66d9ef">as</span> path,
</span></span><span style="display:flex;"><span>        regexp_extract(line, <span style="color:#e6db74">&#39;&#34; (\d+) &#39;</span>, <span style="color:#ae81ff">1</span>)::INT <span style="color:#66d9ef">as</span> status_code,
</span></span><span style="display:flex;"><span>        regexp_extract(line, <span style="color:#e6db74">&#39;&#34; \d+ (\d+)&#39;</span>, <span style="color:#ae81ff">1</span>)::INT <span style="color:#66d9ef">as</span> response_size
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">FROM</span> read_csv_auto(<span style="color:#e6db74">&#39;access.log&#39;</span>, sep<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;\n&#39;</span>, columns<span style="color:#f92672">=</span><span style="color:#960050;background-color:#1e0010">{</span><span style="color:#e6db74">&#39;line&#39;</span>: <span style="color:#e6db74">&#39;VARCHAR&#39;</span><span style="color:#960050;background-color:#1e0010">}</span>)
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">SELECT</span> 
</span></span><span style="display:flex;"><span>    status_code,
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">COUNT</span>(<span style="color:#f92672">*</span>) <span style="color:#66d9ef">as</span> requests,
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">AVG</span>(response_size) <span style="color:#66d9ef">as</span> avg_size,
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">COUNT</span>(<span style="color:#66d9ef">DISTINCT</span> ip) <span style="color:#66d9ef">as</span> unique_ips
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">FROM</span> parsed_logs
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">WHERE</span> <span style="color:#66d9ef">method</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;GET&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">GROUP</span> <span style="color:#66d9ef">BY</span> status_code
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">ORDER</span> <span style="color:#66d9ef">BY</span> requests <span style="color:#66d9ef">DESC</span>;
</span></span></code></pre></div><h2 id="surprising-use-case-5-api-response-wrangler">Surprising Use Case #5: API Response Wrangler</h2>
<p>Got nested JSON from an API? DuckDB flattens it effortlessly:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#75715e">-- Analyzing GitHub API responses
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">WITH</span> api_data <span style="color:#66d9ef">AS</span> (
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> read_json_auto(<span style="color:#e6db74">&#39;github_repos.json&#39;</span>)
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">SELECT</span> 
</span></span><span style="display:flex;"><span>    repo<span style="color:#f92672">-&gt;&gt;</span><span style="color:#e6db74">&#39;name&#39;</span> <span style="color:#66d9ef">as</span> repo_name,
</span></span><span style="display:flex;"><span>    repo<span style="color:#f92672">-&gt;&gt;</span><span style="color:#e6db74">&#39;stargazers_count&#39;</span> <span style="color:#66d9ef">as</span> stars,
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">owner</span><span style="color:#f92672">-&gt;&gt;</span><span style="color:#e6db74">&#39;login&#39;</span> <span style="color:#66d9ef">as</span> <span style="color:#66d9ef">owner</span>,
</span></span><span style="display:flex;"><span>    (repo<span style="color:#f92672">-&gt;&gt;</span><span style="color:#e6db74">&#39;created_at&#39;</span>)::<span style="color:#66d9ef">TIMESTAMP</span> <span style="color:#66d9ef">as</span> created_date,
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">unnest</span>(topics) <span style="color:#66d9ef">as</span> topic
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">FROM</span> api_data
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">WHERE</span> (repo<span style="color:#f92672">-&gt;&gt;</span><span style="color:#e6db74">&#39;stargazers_count&#39;</span>)::INT <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">ORDER</span> <span style="color:#66d9ef">BY</span> stars <span style="color:#66d9ef">DESC</span>;
</span></span></code></pre></div><h2 id="surprising-use-case-6-the-local-data-lake">Surprising Use Case #6: The Local Data Lake</h2>
<p>Transform your laptop into a mini data lake:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#75715e">-- Create views over various data sources
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">CREATE</span> <span style="color:#66d9ef">VIEW</span> sales <span style="color:#66d9ef">AS</span> 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> read_parquet(<span style="color:#e6db74">&#39;s3://bucket/sales/*.parquet&#39;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">CREATE</span> <span style="color:#66d9ef">VIEW</span> customers <span style="color:#66d9ef">AS</span> 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> postgres_scan(<span style="color:#e6db74">&#39;postgresql://prod/customers&#39;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">CREATE</span> <span style="color:#66d9ef">VIEW</span> products <span style="color:#66d9ef">AS</span> 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> <span style="color:#e6db74">&#39;local_products.csv&#39;</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- Query across all sources
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">SELECT</span> 
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">c</span>.customer_name,
</span></span><span style="display:flex;"><span>    p.product_name,
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">SUM</span>(s.amount) <span style="color:#66d9ef">as</span> total_spent
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">FROM</span> sales s
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">JOIN</span> customers <span style="color:#66d9ef">c</span> <span style="color:#66d9ef">ON</span> s.customer_id <span style="color:#f92672">=</span> <span style="color:#66d9ef">c</span>.id
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">JOIN</span> products p <span style="color:#66d9ef">ON</span> s.product_id <span style="color:#f92672">=</span> p.id
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">WHERE</span> s.sale_date <span style="color:#f92672">&gt;</span> <span style="color:#e6db74">&#39;2024-01-01&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">GROUP</span> <span style="color:#66d9ef">BY</span> <span style="color:#66d9ef">c</span>.customer_name, p.product_name
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">ORDER</span> <span style="color:#66d9ef">BY</span> total_spent <span style="color:#66d9ef">DESC</span>;
</span></span></code></pre></div><p>No ETL. No data movement. Just federated queries across formats and locations.</p>
<h2 id="performance-that-surprises">Performance That Surprises</h2>
<p>Let&rsquo;s talk numbers. Processing a 10GB CSV file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># PostgreSQL with COPY (after creating table)</span>
</span></span><span style="display:flex;"><span>Time: <span style="color:#ae81ff">4</span> minutes <span style="color:#ae81ff">32</span> seconds
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Pandas read_csv</span>
</span></span><span style="display:flex;"><span>Time: <span style="color:#ae81ff">2</span> minutes <span style="color:#ae81ff">18</span> seconds
</span></span><span style="display:flex;"><span>Memory: 15GB
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># DuckDB</span>
</span></span><span style="display:flex;"><span>Time: <span style="color:#ae81ff">31</span> seconds
</span></span><span style="display:flex;"><span>Memory: 2.1GB
</span></span></code></pre></div><p>But here&rsquo;s the kicker â€“ with DuckDB, you can query the file without loading it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#75715e">-- This runs in 1.2 seconds and uses 200MB RAM
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">SELECT</span> <span style="color:#66d9ef">COUNT</span>(<span style="color:#f92672">*</span>), <span style="color:#66d9ef">AVG</span>(amount) 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">FROM</span> read_csv_auto(<span style="color:#e6db74">&#39;huge_file.csv&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">WHERE</span> category <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;Electronics&#39;</span>;
</span></span></code></pre></div><h2 id="when-duckdb-isnt-the-answer">When DuckDB Isn&rsquo;t the Answer</h2>
<p>DuckDB excels at analytical workloads, but it&rsquo;s not for everything:</p>
<p><strong>Don&rsquo;t use DuckDB for:</strong></p>
<ul>
<li>High-concurrency transactional systems (use PostgreSQL)</li>
<li>Real-time streaming with millisecond latency (use Kafka + Flink)</li>
<li>Persistent production databases (use PostgreSQL)</li>
<li>Distributed processing of petabytes (use Spark/Presto)</li>
</ul>
<p><strong>Definitely try DuckDB for:</strong></p>
<ul>
<li>Data exploration and analysis</li>
<li>ETL/ELT pipelines</li>
<li>Processing files without loading</li>
<li>Local analytical applications</li>
<li>Prototyping data pipelines</li>
<li>One-off data transformations</li>
<li>Embedded analytics in applications</li>
</ul>
<h2 id="real-world-pipeline-transformation">Real-World Pipeline Transformation</h2>
<p>Here&rsquo;s a before/after from a real project:</p>
<p><strong>Before (Apache Airflow + Spark):</strong></p>
<ul>
<li>Download files from S3 (7 minutes)</li>
<li>Load into Spark DataFrame (3 minutes)</li>
<li>Transform and aggregate (2 minutes)</li>
<li>Write to PostgreSQL (4 minutes)</li>
<li>Total: 16 minutes, $15 in compute costs</li>
</ul>
<p><strong>After (DuckDB):</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#75715e">-- Entire pipeline in one query
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">COPY</span> (
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">WITH</span> cleaned_data <span style="color:#66d9ef">AS</span> (
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">SELECT</span> 
</span></span><span style="display:flex;"><span>            customer_id,
</span></span><span style="display:flex;"><span>            DATE_TRUNC(<span style="color:#e6db74">&#39;day&#39;</span>, <span style="color:#66d9ef">timestamp</span>) <span style="color:#66d9ef">as</span> date,
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">SUM</span>(amount) <span style="color:#66d9ef">as</span> daily_total,
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">COUNT</span>(<span style="color:#f92672">*</span>) <span style="color:#66d9ef">as</span> transaction_count
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">FROM</span> read_parquet(<span style="color:#e6db74">&#39;s3://bucket/transactions/*.parquet&#39;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">WHERE</span> amount <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span> 
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">AND</span> <span style="color:#66d9ef">timestamp</span> <span style="color:#f92672">&gt;</span> <span style="color:#66d9ef">CURRENT_DATE</span> <span style="color:#f92672">-</span> INTERVAL <span style="color:#e6db74">&#39;90 days&#39;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">GROUP</span> <span style="color:#66d9ef">BY</span> customer_id, date
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> cleaned_data
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">WHERE</span> daily_total <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>) <span style="color:#66d9ef">TO</span> postgres_scan(<span style="color:#e6db74">&#39;postgresql://analytics/customer_metrics&#39;</span>);
</span></span></code></pre></div><ul>
<li>Total: 1 minute, $0(ish) in compute costs</li>
</ul>
<h2 id="getting-started">Getting Started</h2>
<p>Installation is refreshingly simple:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Python</span>
</span></span><span style="display:flex;"><span>pip install duckdb
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># CLI</span>
</span></span><span style="display:flex;"><span>brew install duckdb  <span style="color:#75715e"># macOS</span>
</span></span></code></pre></div><p>Your first query:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> duckdb
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Query any file</span>
</span></span><span style="display:flex;"><span>result <span style="color:#f92672">=</span> duckdb<span style="color:#f92672">.</span>sql(<span style="color:#e6db74">&#34;SELECT * FROM &#39;data.csv&#39; LIMIT 5&#34;</span>)<span style="color:#f92672">.</span>fetchall()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Or use it like a real database</span>
</span></span><span style="display:flex;"><span>con <span style="color:#f92672">=</span> duckdb<span style="color:#f92672">.</span>connect(<span style="color:#e6db74">&#39;my_analysis.db&#39;</span>)
</span></span><span style="display:flex;"><span>con<span style="color:#f92672">.</span>execute(<span style="color:#e6db74">&#34;CREATE TABLE results AS SELECT * FROM &#39;huge_dataset.parquet&#39;&#34;</span>)
</span></span></code></pre></div><h2 id="the-hidden-magic">The Hidden Magic</h2>
<p>What makes DuckDB special isn&rsquo;t just speed â€“ it&rsquo;s removing friction:</p>
<ul>
<li>No more writing custom parsers for each file format</li>
<li>No more moving data between systems</li>
<li>No more managing clusters for simple aggregations</li>
<li>No more choosing between SQL and DataFrame APIs</li>
<li>No more explaining why you need a Spark cluster for a 5GB file</li>
</ul>
<p>Instead, you just write SQL and it works.</p>
<h2 id="conclusion">Conclusion</h2>
<p>DuckDB represents a shift in how we think about data processing. It&rsquo;s not trying to replace your production database or your streaming platform. It&rsquo;s filling a gap we didn&rsquo;t know existed â€“ the space between &ldquo;too big for Excel&rdquo; and &ldquo;too small for Spark.&rdquo;</p>
<p>The next time you&rsquo;re faced with messy CSVs, nested JSON, or files scattered across S3, don&rsquo;t spin up a cluster. Don&rsquo;t write a complex Python script. Just point DuckDB at your data and write some SQL.</p>
<p>Because sometimes the best solution isn&rsquo;t the most sophisticated one â€“ it&rsquo;s the one that just works.</p>
<hr>
<p><em>Have you tried DuckDB for unconventional use cases? What surprised you?</em></p>
<p><em>Originally shared on <a href="https://linkedin.com/in/moorelloyd">LinkedIn</a></em></p>
<ul class="pa0">
  
   <li class="list di">
     <a href="/tags/duckdb/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">Duckdb</a>
   </li>
  
   <li class="list di">
     <a href="/tags/data-processing/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">Data-Processing</a>
   </li>
  
   <li class="list di">
     <a href="/tags/analytics/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">Analytics</a>
   </li>
  
   <li class="list di">
     <a href="/tags/sql/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">Sql</a>
   </li>
  
   <li class="list di">
     <a href="/tags/performance/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">Performance</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="https://lloydmoore.com/" >
    &copy;  Lloyd Moore 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>
